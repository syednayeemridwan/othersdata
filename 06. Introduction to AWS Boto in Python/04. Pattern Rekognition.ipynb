{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the Rekognition client to detect the labels for image1. Return a maximum of 1 label.\n",
    "- Detect the labels for image2 and print the response's labels.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use Rekognition client to detect labels\n",
    "# image1_response = rekog.detect_labels(\n",
    "#     # Specify the image as an S3Object; Return one label\n",
    "#     Image=image1, MaxLabels=1)\n",
    "\n",
    "# # Print the labels\n",
    "# print(image1_response['Labels'])\n",
    "\n",
    "# # Use Rekognition client to detect labels\n",
    "# image2_response = rekog.detect_labels(\n",
    "#     # Specify the image as an S3Object; Return one label\n",
    "#     Image=image2, MaxLabels=1)\n",
    "\n",
    "# # Print the labels\n",
    "# print(image2_response['Labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iterate over each element of the 'Labels' key in response.\n",
    "- Once you encounter a label with the name 'Cat', iterate over the label's instance.\n",
    "- If an instance's confidence level exceeds 85, increment cat_counts by 1.\n",
    "- Print the final cat count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an empty counter variable\n",
    "# cats_count = 0\n",
    "# # Iterate over the labels in the response\n",
    "# for label in response['Labels']:\n",
    "#     # Find the cat label, look over the detected instances\n",
    "#     if label['Name'] == 'Cat':\n",
    "#         for instance in label['Instances']:\n",
    "#             # Only count instances with confidence > 85\n",
    "#             if (instance['Confidence'] > 85):\n",
    "#                 cats_count += 1\n",
    "# # Print count of cats\n",
    "# print(cats_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iterate over each detected text in response, and append each detected text to words if the text's type is 'WORD'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create empty list of words\n",
    "# words = []\n",
    "# # Iterate over the TextDetections in the response dictionary\n",
    "# for text_detection in response['TextDetections']:\n",
    "#   \t# If TextDetection type is WORD, append it to words list\n",
    "#     if text_detection['Type'] == 'WORD':\n",
    "#         # Append the detected text\n",
    "#         words.append(text_detection['DetectedText'])\n",
    "# # Print out the words list\n",
    "# print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iterate over each detected text in response, and append each detected text to lines if the text's type is 'LINE'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create empty list of lines\n",
    "# lines = []\n",
    "# # Iterate over the TextDetections in the response dictionary\n",
    "# for text_detection in response['TextDetections']:\n",
    "#   \t# If TextDetection type is Line, append it to lines list\n",
    "#     if text_detection['Type'] == 'LINE':\n",
    "#         # Append the detected text\n",
    "#         lines.append(text_detection['DetectedText'])\n",
    "# # Print out the words list\n",
    "# print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each row in the DataFrame, detect the dominant language.\n",
    "- Assign the first selected language to the 'lang' column.\n",
    "- Count the total number of posts in Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For each dataframe row\n",
    "# for index, row in dumping_df.iterrows():\n",
    "#     # Get the public description field\n",
    "#     description =dumping_df.loc[index, 'public_description']\n",
    "#     if description != '':\n",
    "#         # Detect language in the field content\n",
    "#         resp = comprehend.detect_dominant_language(Text=description)\n",
    "#         # Assign the top choice language to the lang column.\n",
    "#         dumping_df.loc[index, 'lang'] = resp['Languages'][0]['LanguageCode']\n",
    "        \n",
    "# # Count the total number of spanish posts\n",
    "# spanish_post_ct = len(dumping_df[dumping_df.lang == 'es'])\n",
    "# # Print the result\n",
    "# print(\"{} posts in Spanish\".format(spanish_post_ct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each row in the DataFrame, translate it to English.\n",
    "- Store the original language in the original_lang column.\n",
    "- Store the new translation in the translated_desc column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in dumping_df.iterrows():\n",
    "#   \t# Get the public_description into a variable\n",
    "#     description = dumping_df.loc[index, 'public_description']\n",
    "#     if description != '':\n",
    "#       \t# Translate the public description\n",
    "#         resp = translate.translate_text(\n",
    "#             Text=description, \n",
    "#             SourceLanguageCode='auto', TargetLanguageCode='en')\n",
    "#         # Store original language in original_lang column\n",
    "#         dumping_df.loc[index, 'original_lang'] = resp['SourceLanguageCode']\n",
    "#         # Store the translation in the translated_desc column\n",
    "#         dumping_df.loc[index, 'translated_desc'] = resp['TranslatedText']\n",
    "# # Preview the resulting DataFrame\n",
    "# dumping_df = dumping_df[['service_request_id', 'original_lang', 'translated_desc']]\n",
    "# dumping_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detect the sentiment of 'public_description' for every row.\n",
    "- Store the result in the 'sentiment' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in dumping_df.iterrows():\n",
    "#   \t# Get the translated_desc into a variable\n",
    "#     description = dumping_df.loc[index, 'public_description']\n",
    "#     if description != '':\n",
    "#       \t# Get the detect_sentiment response\n",
    "#         response = comprehend.detect_sentiment(\n",
    "#           Text=description, \n",
    "#           LanguageCode='en')\n",
    "#         # Get the sentiment key value into sentiment column\n",
    "#         dumping_df.loc[index, 'sentiment'] = response['Sentiment']\n",
    "# # Preview the dataframe\n",
    "# dumping_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For every DataFrame row, detect the dominant language.\n",
    "- Use the detected language to determine the sentiment of the description.\n",
    "- Group the DataFrame by the 'sentiment' and 'lang' columns in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in scooter_requests.iterrows():\n",
    "#   \t# For every DataFrame row\n",
    "#     desc = scooter_requests.loc[index, 'public_description']\n",
    "#     if desc != '':\n",
    "#       \t# Detect the dominant language\n",
    "#         resp = comprehend.detect_dominant_language(Text=desc)\n",
    "#         lang_code = resp['Languages'][0]['LanguageCode']\n",
    "#         scooter_requests.loc[index, 'lang'] = lang_code\n",
    "#         # Use the detected language to determine sentiment\n",
    "#         scooter_requests.loc[index, 'sentiment'] = comprehend.detect_sentiment(\n",
    "#           Text=desc, \n",
    "#           LanguageCode=lang_code)['Sentiment']\n",
    "# # Perform a count of sentiment by group.\n",
    "# counts = scooter_requests.groupby(['sentiment', 'lang']).count()\n",
    "# counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the SNS topic ARN for 'scooter_notifications'.\n",
    "- For every row, if sentiment is 'NEGATIVE' and there is an image of a scooter, construct a message to send.\n",
    "- Publish the notification to the SNS topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get topic ARN for scooter notifications\n",
    "# topic_arn = sns.create_topic(Name='scooter_notifications')['TopicArn']\n",
    "\n",
    "# for index, row in scooter_requests.iterrows():\n",
    "#     # Check if notification should be sent\n",
    "#     if (row['sentiment'] == 'NEGATIVE') & (row['img_scooter'] == 1):\n",
    "#         # Construct a message to publish to the scooter team.\n",
    "#         message = \"Please remove scooter at {}, {}. Description: {}\".format(\n",
    "#             row['long'], row['lat'], row['public_description'])\n",
    "\n",
    "#         # Publish the message to the topic!\n",
    "#         sns.publish(TopicArn = topic_arn,\n",
    "#                     Message = message, \n",
    "#                     Subject = \"Scooter Alert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('env_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e949e87132dd83f1a7623eb88007e3532b03b66b77111be347aa4a383049722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
